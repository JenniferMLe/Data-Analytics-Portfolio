{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for IMDB Dataset\n",
    "\n",
    "Author: Jennifer Le\n",
    "Date: 1/22/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe code below was used to read in the original titles dataset.\\nTo save space, this 11 million row, nearly 1GB dataset is replaced by a\\nsmaller filtered dataset. \\n\\n# Read in original dataset and delete irrelevant columns and rows\\ndf = pd.read_csv(\"title.basics.tsv\", delimiter=\\'\\t\\', low_memory=False)\\ndf = df.drop(columns=[\\'isAdult\\',\\'originalTitle\\'])\\n\\n# Remove rows where titleType is in list, the ~ symbol negates the isin\\nprint(df[\\'titleType\\'].unique())\\ndf = df[\\n    ~df[\"titleType\"].isin(\\n        [\\'tvEpisode\\',\\'video\\',\\'videoGame\\',\\'tvPilot\\',\\'tvSpecial\\']\\n    )\\n]\\ndf.to_csv(\"titles_reduced.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "The code below was used to read in the original titles dataset.\n",
    "To save space, this 11 million row, nearly 1GB dataset is replaced by a\n",
    "smaller filtered dataset. \n",
    "\n",
    "# Read in original dataset and delete irrelevant columns and rows\n",
    "df = pd.read_csv(\"title.basics.tsv\", delimiter='\\t', low_memory=False)\n",
    "df = df.drop(columns=['isAdult','originalTitle'])\n",
    "\n",
    "# Remove rows where titleType is in list, the ~ symbol negates the isin\n",
    "print(df['titleType'].unique())\n",
    "df = df[\n",
    "    ~df[\"titleType\"].isin(\n",
    "        ['tvEpisode','video','videoGame','tvPilot','tvSpecial']\n",
    "    )\n",
    "]\n",
    "df.to_csv(\"titles_reduced.csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2238148, 7)\n",
      "(1526047, 3)\n",
      "(11401626, 3)\n"
     ]
    }
   ],
   "source": [
    "# add files from google drive to correct folder to \n",
    "# run code block without file-not-found error\n",
    "\n",
    "df_titles = pd.read_csv('../../titles_reduced.csv')\n",
    "df_ratings = pd.read_csv('../../ratings.tsv', delimiter='\\t', low_memory=False)\n",
    "df_crew = pd.read_csv('../../crew.tsv', delimiter='\\t', low_memory=False)\n",
    "\n",
    "print(df_titles.shape)\n",
    "print(df_ratings.shape)\n",
    "print(df_crew.shape)\n",
    "\n",
    "df_combined = pd.merge(df_titles, df_ratings, on='tconst', how='inner')\n",
    "df_combined = pd.merge(df_combined, df_crew, on='tconst', how='inner')\n",
    "\n",
    "# replace null values with 0 or empty space\n",
    "df_combined['startYear'] = df_combined['startYear'].replace({'\\\\N': '0'}) \n",
    "df_combined['endYear'] = df_combined['endYear'].replace({'\\\\N': '0'})        \n",
    "df_combined['runtimeMinutes'] = df_combined['runtimeMinutes'].replace({'\\\\N':'0'})\n",
    "df_combined['genres'] = df_combined['genres'].replace({'\\\\N':''}) \n",
    "df_combined['directors'] = df_combined['directors'].replace({'\\\\N':''}) \n",
    "df_combined['writers'] = df_combined['writers'].replace({'\\\\N':''}) \n",
    "\n",
    "# convert types to save space\n",
    "df_combined['endYear'] = df_combined['endYear'].astype('int32')   \n",
    "df_combined['runtimeMinutes'] = df_combined['runtimeMinutes'].astype('int32')       \n",
    "df_combined['startYear'] = df_combined['startYear'].astype('int32')  \n",
    "\n",
    "df_combined.to_csv('result.csv', index=False)\n",
    "print(df_combined.shape)\n",
    "print(df_combined.dtypes)\n",
    "\n",
    "df_combined.to_csv('imdb_dataset_original.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv('imdb_dataset_original.csv')\n",
    "df_names = pd.read_csv('../../names.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split columns containing multiple values \n",
    "df_genres_split = df_combined['genres'].str.split(pat=',',expand=True, n=2)\n",
    "df_directors_split = df_combined['directors'].str.split(pat=',',expand=True, n=3)\n",
    "df_writers_split = df_combined['writers'].str.split(pat=',',expand=True, n=3)\n",
    "df_writers_split.to_csv('result.csv',index=False)\n",
    "\n",
    "# add new columns for the splited genres\n",
    "df_combined['genres'] = df_genres_split[0]\n",
    "df_combined.insert(7, 'genre2', df_genres_split[1])\n",
    "df_combined.insert(8,'genre3',df_genres_split[2])\n",
    "\n",
    "# add new columns for the splited directors\n",
    "df_combined['directors'] = df_directors_split[0]\n",
    "df_combined.insert(12, 'director2', df_directors_split[1])\n",
    "df_combined.insert(13, 'director3', df_directors_split[2])\n",
    "\n",
    "# add new columns for the splited writers\n",
    "df_combined['writers'] = df_writers_split[0]\n",
    "df_combined['writer2'] = df_writers_split[1]\n",
    "df_combined['writer3'] = df_writers_split[2]\n",
    "\n",
    "# change column names\n",
    "df_combined = df_combined.rename(columns={\n",
    "        'directors':'director1',\n",
    "        'writers':'writer1',\n",
    "        'genres':'genre1'\n",
    "    }\n",
    ")\n",
    "\n",
    "# function to replace name id with actual name\n",
    "def replace_id_with_names(df_combined, df_names, column_name):\n",
    "    df_combined = pd.merge(df_combined,df_names, \n",
    "                        left_on=column_name, right_on='nconst',how ='left')\n",
    "\n",
    "    df_combined[column_name] = df_combined['primaryName']\n",
    "    df_combined = df_combined.drop(columns=['nconst','primaryName'])\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "# replace id of directors and writers\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'director1')\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'director2')\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'director3')\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'writer1')\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'writer2')\n",
    "df_combined = replace_id_with_names(df_combined, df_names, 'writer3')\n",
    "\n",
    "df_combined.to_csv('imdb_dataset_transformed.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs418env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
